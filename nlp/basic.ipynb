{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6597d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d244697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello  my name is  yash'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"hello@ my name is #yash\"\n",
    "cleaned_text= re.sub(r\"[^a-zA-z0-9]\",\" \",input)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78d1da3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello my name is  yash12638'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"hello@my name is #yash12638\"\n",
    "cleaned_text= re.sub(r\"[^a-zA-z0-9]\",\" \",input)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "183b444c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello my name is  yash     '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"hello@my name is #yash12638\"\n",
    "cleaned_text= re.sub(r\"[^a-zA-Z]\",\" \",input)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3453b568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.2.0)\n",
      "i am going\n"
     ]
    }
   ],
   "source": [
    "! pip install contractions\n",
    "import contractions\n",
    "text =\"i'm going\"\n",
    "expanded_text= contractions.fix(text)\n",
    "print(expanded_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9d15067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60f157f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36d28bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9257973e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', '@', 'my', 'name', 'is', '#', 'himanshu']\n",
      "hello my name is himanshu\n"
     ]
    }
   ],
   "source": [
    "input = \"hello@ my name is #himanshu\"\n",
    "tokens= nltk.word_tokenize(input)#convert into tokrns like \"hello\"\n",
    "print(tokens)\n",
    "\n",
    "clean_text =[token for token in tokens if token.isalnum()]#\n",
    "cleaned_text=' '.join(clean_text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc421eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dd6447",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Ram is https://pypi.org/project/nltk/shayam\"## removve html\n",
    "import re\n",
    "re.sub(r\"<.*?>\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b5a1572",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_word_dict = {\n",
    "    \"u\": \"you\",\n",
    "    \"r\": \"are\",\n",
    "    \"b4\": \"before\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"l8r\": \"later\",\n",
    "    \"idk\": \"I don’t know\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"lemme\": \"let me\",\n",
    "    \"dunno\": \"don’t know\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"pls\": \"please\",\n",
    "    \"ppl\": \"people\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"afk\": \"away from keyboard\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"hbu\": \"how about you\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"ttys\": \"talk to you soon\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38983510",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_text = \"omg idk what  u r taking about \"\n",
    "def normalize_text(chat_text):\n",
    "    words =chat_text.split()\n",
    "    normalized_words=[chat_word_dict.get(word.lower(), word) for word in words]\n",
    "    return\" \".join(normalized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd945ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_text=normalize_text(chat_text = \"omg idk what ur talking about lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "352af280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oh my god I don’t know what ur talking about laugh out loud'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8e73292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.9->textblob) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.9->textblob) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 624.3/624.3 kB 7.7 MB/s eta 0:00:00\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.19.0\n"
     ]
    }
   ],
   "source": [
    "! pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b99a90bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my name is wash\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "text = \"mye nameee is yash\"\n",
    "spelling_correct= TextBlob(text).correct()\n",
    "print(spelling_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "add52504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.14.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from SpeechRecognition) (4.14.0)\n",
      "Requirement already satisfied: pyaudio in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.14)\n"
     ]
    }
   ],
   "source": [
    "# Speech to text(stt)\n",
    "! pip install SpeechRecognition\n",
    "! pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ffe04052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speak now\n",
      "you said hello my name is Yash Sharma\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "recognizer = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"speak now\")\n",
    "    audio =recognizer.listen(source)\n",
    "try:\n",
    "    text = recognizer.recognize_google(audio)\n",
    "    print(\"you said\", text)\n",
    "except:\n",
    "    print(\"sorry could not recognize your voice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "905db01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gtts in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.5.4)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gtts) (2.32.4)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gtts) (8.1.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->gtts) (2025.6.15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! pip install gtts\n",
    "from gtts import gTTS\n",
    "import os\n",
    "text = \"Hello welcome to my home \"\n",
    "tts = gTTS(text = text , lang=\"en\")\n",
    "tts.save(\"welcome.mp3\")\n",
    "os.system(\"welcome.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ac92cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11789bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = {\"text\":[\"people watch Aiyug\",\"Aiyug watch Aiyug\",\"People write comment\",\"Aiyug write comment\"],\"Output\":[1,1,0,0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74603a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "text =pd.DataFrame(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ebdc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch Aiyug</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aiyug watch Aiyug</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aiyug write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   text  Output\n",
       "0    people watch Aiyug       1\n",
       "1     Aiyug watch Aiyug       1\n",
       "2  People write comment       0\n",
       "3   Aiyug write comment       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75286e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn .feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb596d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv =CountVectorizer(lowercase=True, stop_words='english', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6598221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow =cv.fit_transform(text['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6542efe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': 2, 'watch': 3, 'aiyug': 0, 'write': 4, 'comment': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b427c47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 0]]\n",
      "[[1 0 0 1 0]]\n",
      "[[0 1 1 0 1]]\n",
      "[[1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())\n",
    "print(bow[1].toarray())\n",
    "print(bow[2].toarray())\n",
    "print(bow[3].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a13d5814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b0de218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams:- [('I', 'love'), ('love', 'natural'), ('natural', 'language'), ('language', 'processing')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"I love natural language processing\"\n",
    "tokens = word_tokenize(text)\n",
    "n =2\n",
    "\n",
    "bigrams =list(ngrams(tokens,n))\n",
    "print(\"bigrams:-\",bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa4621f",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f3875cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document:- 1\n",
      "language: 0.5465\n",
      "love: 0.3227\n",
      "natural: 0.5465\n",
      "processing: 0.5465\n",
      "document:- 2\n",
      "learning: 0.5478\n",
      "love: 0.4254\n",
      "machine: 0.7203\n",
      "document:- 3\n",
      "deep: 0.7203\n",
      "learning: 0.5478\n",
      "love: 0.4254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "text = [\"i love natural language processing\", \"i love machine learning\", \"i love deep learning\"]\n",
    "vectorizer=TfidfVectorizer()\n",
    "tfidf_matrix=vectorizer.fit_transform(text)\n",
    "#print(tfidf_matrix.toarray())\n",
    "feature_names=vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "for doc_index, doc in enumerate(tfidf_matrix.toarray()):\n",
    "    print(\"document:-\", doc_index+1)\n",
    "    for word_index, score in enumerate (doc):\n",
    "        if score> 0:\n",
    "            print(f\"{feature_names [word_index]}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8bb649e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['deep', 'language', 'learning', 'love', 'machine', 'natural',\n",
       "       'processing'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1497d7ff",
   "metadata": {},
   "source": [
    "Part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c417c220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp311-cp311-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.32.4)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (25.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.0)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.6.15)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.21.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.3.0.post1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Downloading spacy-3.8.7-cp311-cp311-win_amd64.whl (14.9 MB)\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/14.9 MB 4.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.8/14.9 MB 4.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.9/14.9 MB 4.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.4/14.9 MB 4.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.2/14.9 MB 4.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.2/14.9 MB 4.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.6/14.9 MB 4.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.9/14.9 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.4/14.9 MB 5.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 10.7/14.9 MB 5.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.6/14.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.2/14.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.9/14.9 MB 5.7 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp311-cp311-win_amd64.whl (24 kB)\n",
      "Downloading preshed-3.0.10-cp311-cp311-win_amd64.whl (117 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 1.3/2.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 6.4 MB/s eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp311-cp311-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 632.6/632.6 kB 6.0 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.6-cp311-cp311-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 7.5 MB/s eta 0:00:00\n",
      "Downloading blis-1.3.0-cp311-cp311-win_amd64.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.2 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.9/6.2 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 7.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.2 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 7.2 MB/s eta 0:00:00\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.21.1-py3-none-any.whl (52 kB)\n",
      "Downloading smart_open-7.3.0.post1-py3-none-any.whl (61 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.6/5.4 MB 8.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.1/5.4 MB 8.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.4 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 8.2 MB/s eta 0:00:00\n",
      "Downloading marisa_trie-1.2.1-cp311-cp311-win_amd64.whl (152 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: cymem, wasabi, typing-inspection, spacy-loggers, spacy-legacy, smart-open, shellingham, pydantic-core, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, annotated-types, srsly, pydantic, preshed, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
      "\n",
      "   - --------------------------------------  1/24 [wasabi]\n",
      "   ----- ----------------------------------  3/24 [spacy-loggers]\n",
      "   ------ ---------------------------------  4/24 [spacy-legacy]\n",
      "   -------- -------------------------------  5/24 [smart-open]\n",
      "   -------- -------------------------------  5/24 [smart-open]\n",
      "   ----------- ----------------------------  7/24 [pydantic-core]\n",
      "   ---------------- ----------------------- 10/24 [cloudpathlib]\n",
      "   ---------------- ----------------------- 10/24 [cloudpathlib]\n",
      "   -------------------- ------------------- 12/24 [blis]\n",
      "   ----------------------- ---------------- 14/24 [srsly]\n",
      "   ----------------------- ---------------- 14/24 [srsly]\n",
      "   ----------------------- ---------------- 14/24 [srsly]\n",
      "   ----------------------- ---------------- 14/24 [srsly]\n",
      "   ----------------------- ---------------- 14/24 [srsly]\n",
      "   ----------------------- ---------------- 14/24 [srsly]\n",
      "   ----------------------- ---------------- 14/24 [srsly]\n",
      "   ----------------------- ---------------- 14/24 [srsly]\n",
      "   ----------------------- ---------------- 14/24 [srsly]\n",
      "   ------------------------- -------------- 15/24 [pydantic]\n",
      "   ------------------------- -------------- 15/24 [pydantic]\n",
      "   ------------------------- -------------- 15/24 [pydantic]\n",
      "   ------------------------- -------------- 15/24 [pydantic]\n",
      "   ------------------------- -------------- 15/24 [pydantic]\n",
      "   ------------------------- -------------- 15/24 [pydantic]\n",
      "   ------------------------- -------------- 15/24 [pydantic]\n",
      "   ------------------------- -------------- 15/24 [pydantic]\n",
      "   ---------------------------- ----------- 17/24 [language-data]\n",
      "   ---------------------------- ----------- 17/24 [language-data]\n",
      "   ---------------------------- ----------- 17/24 [language-data]\n",
      "   ---------------------------- ----------- 17/24 [language-data]\n",
      "   ---------------------------- ----------- 17/24 [language-data]\n",
      "   ------------------------------ --------- 18/24 [typer]\n",
      "   ------------------------------ --------- 18/24 [typer]\n",
      "   ------------------------------- -------- 19/24 [langcodes]\n",
      "   --------------------------------- ------ 20/24 [confection]\n",
      "   ----------------------------------- ---- 21/24 [weasel]\n",
      "   ----------------------------------- ---- 21/24 [weasel]\n",
      "   ------------------------------------ --- 22/24 [thinc]\n",
      "   ------------------------------------ --- 22/24 [thinc]\n",
      "   ------------------------------------ --- 22/24 [thinc]\n",
      "   ------------------------------------ --- 22/24 [thinc]\n",
      "   ------------------------------------ --- 22/24 [thinc]\n",
      "   ------------------------------------ --- 22/24 [thinc]\n",
      "   ------------------------------------ --- 22/24 [thinc]\n",
      "   ------------------------------------ --- 22/24 [thinc]\n",
      "   ------------------------------------ --- 22/24 [thinc]\n",
      "   ------------------------------------ --- 22/24 [thinc]\n",
      "   ------------------------------------ --- 22/24 [thinc]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   -------------------------------------- - 23/24 [spacy]\n",
      "   ---------------------------------------- 24/24 [spacy]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 blis-1.3.0 catalogue-2.0.10 cloudpathlib-0.21.1 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.13 preshed-3.0.10 pydantic-2.11.7 pydantic-core-2.33.2 shellingham-1.5.4 smart-open-7.3.0.post1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 typer-0.16.0 typing-inspection-0.4.1 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    }
   ],
   "source": [
    "! pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3da9ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c0e1d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos =spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ac215d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc =pos(\"i love natural langage processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8abaf1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i love natural langage processing'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "605b0de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[3].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af1a2260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "print(st.stem(\"loving\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99205868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'love'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(st.stem(\"loving\"))\n",
    "st.stem(\"loving\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
